{
  "hash": "aa6b2d5554b92c87a24f707e21301d1f",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Joint analysis of E1a and E1b\"\noutput: html\nauthor: \"Ven Popov\"\ndate: \"2023-08-30\"\ndate-modified: \"2023-08-30\"\n---\n\n\n\n::: {.callout-note}\nThese are legacy analyses scripts from my older project structure. The scripts are kept here for reference and reproducibility purposes until I completely transition to the new structure. I want to replicate the analysis in the new project structure to make sure everything is working as expected. Nowadays I also have better solutions than `if(file.exists())` for managing the data and model fits, so I will update the script accordingly.\n:::\n\n\n\n## Load and clean data\n\nJoint analysis of Experiment 1a and 1b. Load libraries:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(lme4)\nlibrary(Rmisc)\nlibrary(tidyverse)\nlibrary(here)\nlibrary(brms)\n\n\ndodge <- position_dodge(1)\ntheme_set(theme_dark(base_size = 11))\n```\n:::\n\n\n\n\nLoad and combine data that was preprocessed with David's script.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# if the script has been run before, preload the data and model fits\nR_output_file <- here::here('output/exp1_updated.RData')\n\nif (!file.exists(R_output_file)) {\n  exp1a <- read.csv(here::here('data/Expmt1a-PreReg/Processed/LongFormAnalysisData.csv'))\n  exp1b <- read.csv(here::here('data/Expmt1b-PreReg/Processed/LongFormAnalysisData.csv'))\n  exp1a$exp <- '1a'\n  exp1b$exp <- '1b'\n  exp1b$participant <- exp1b$participant\n  dat <- bind_rows(exp1a,exp1b)\n  \n  # code sample (students vs prolific)\n  dat <- dat %>% \n    mutate(sample = ifelse(nchar(participant) < 6, 'students','prolific'))\n  \n  # Apply David's trimming script\n  procTrim <- dat %>% \n    filter(ProportionTonesCorrect == 1) %>% \n    mutate(rt = rt*1000) %>%  # Make RTs milliseconds\n    group_by(participant) %>% # grouping by participant so SD per participant calculated - similar to perParticipant = True in Trimr\n    filter(rt >= 200)%>%      # remove anything <200ms as this likely means they were anticipating response rather than reacting - same as Joseph & Morey 2021\n    filter(rt < 5000) %>%       \n    filter(abs(rt - mean(rt))/sd(rt) <= 3) \n  \n  # This just gives a quick summary count of amount of data before and after trimming.\n  nrow(dat) #original number\n  nrow(procTrim) #number remaining\n  nrow(dat) - nrow(procTrim) #number removed  \n  \n  ##Rename variables to align with previous research\n  procTrim[procTrim == \"LeadTone_RT1\"] <- \"Lead-in-4\"\n  procTrim[procTrim == \"LeadTone_RT2\"] <- \"Lead-in-3\"\n  procTrim[procTrim == \"LeadTone_RT3\"] <- \"Lead-in-2\"\n  procTrim[procTrim == \"LeadTone_RT4\"] <- \"Lead-in-1\"\n  procTrim[procTrim == \"MainTone_RT1\"] <- \"List-1\"\n  procTrim[procTrim == \"MainTone_RT2\"] <- \"List-2\"\n  procTrim[procTrim == \"MainTone_RT3\"] <- \"List-3\"\n  procTrim[procTrim == \"MainTone_RT4\"] <- \"List-4\"\n  procTrim[procTrim == \"MainTone_RT5\"] <- \"List-5\"\n  procTrim[procTrim == \"MainTone_RT6\"] <- \"List-6\"\n  procTrim[procTrim == \"MainTone_RT7\"] <- \"List-7\"\n  procTrim[procTrim == \"MainTone_RT8\"] <- \"List-8\"\n  procTrim[procTrim == \"MainTone_RT9\"] <- \"List-9\"\n  \n  procTrim <- procTrim %>%  \n    mutate(procPeriod = case_when(grepl(\"Lead-in\", procPos) ~ \"Lead-in\",\n                                  grepl(\"List\", procPos) ~\"Load\")) %>% \n    mutate(procPos = factor(procPos, levels = c(\"Lead-in-4\", \"Lead-in-3\", \"Lead-in-2\", \"Lead-in-1\", \"List-1\", \"List-2\", \"List-3\", \"List-4\", \"List-5\", \"List-6\", \"List-7\", \"List-8\", \"List-9\"))) %>%\n    mutate(ListLength = as.factor(ListLength))%>%\n    mutate(serial_position_abs = as.numeric(gsub('List-','', procPos)),\n           serial_position_rel = serial_position_abs-recallamount) %>% \n    mutate(recallamount = as.factor(recallamount)) %>% \n    ungroup()\n\n} else {\n  load(R_output_file)\n  R_output_file <- here::here('output/exp1_updated.RData')\n}\n```\n:::\n\n\n\n\n\n## Data Visualisation\n\nWe can now plot our tidied and trimmed data. We will relabel some variables and then calculate the summary statistics before plotting.\n\nReproduce the basic plot for both experiments (code from David's script)\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Means for plot, with within-participant SEMs\ngraphRT <- summarySEwithin(ungroup(procTrim), measurevar = \"rt\", withinvars = c(\"ListLength\", \"recallamount\", \"procPos\", \"procPeriod\"), betweenvars = \"exp\", idvar = \"participant\")\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAutomatically converting the following non-factors to factors: exp, procPeriod\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(graphRT, aes(procPos, rt, group = interaction(procPeriod, ListLength))) +\n  geom_point(data = graphRT, mapping = aes(x = procPos, y = rt, color = ListLength), size = 2, alpha = 1 / 3, position = dodge) +\n  geom_line(data = graphRT, mapping = aes(x = procPos, y = rt, colour = ListLength, group = interaction(procPeriod, ListLength)), position = dodge) +\n  geom_errorbar(aes(ymin = rt - se, ymax = rt + se, colour = ListLength), width = .15, position = position_dodge(.9)) +\n  facet_grid(exp ~ recallamount, scales = \"free\") +\n  scale_colour_manual(values = viridisLite::viridis(8, direction = -1), name = \"List Length\") +\n  xlab(\"Serial Position\") +\n  ylab(\"Mean Response Time (ms)\") +\n  # scale_y_continuous(breaks=seq(600, 1400, 50), limits = c(600, 1400))+\n  # ylim(250, 800) +\n  theme(axis.text.x = element_text(angle = 70, hjust = 1)) \n```\n\n::: {.cell-output-display}\n![](JointAnalyses-1ab-Ven_files/figure-html/PlotGraphs-1.png){width=672}\n:::\n:::\n\n\n\n\nPlot RT collapsed over list-length and as a function of serial position relative to N. Position 0 means the 2nd item in recall2 condition or the 4th item in the recall4 condition. Separately for both experiments\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Means for plot, with within-participant SEMs\ngraphRT <- procTrim %>%\n  filter(procPeriod == \"Load\") %>%\n  summarySEwithin(measurevar = \"rt\", withinvars = c(\"recallamount\", \"serial_position_rel\"), betweenvars = \"exp\", idvar = \"participant\") %>%\n  mutate(serial_position_rel = as.numeric(as.character(serial_position_rel)))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAutomatically converting the following non-factors to factors: exp, serial_position_rel\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(graphRT, aes(serial_position_rel, rt)) +\n  geom_point(data = graphRT, mapping = aes(x = serial_position_rel, y = rt, color = as.factor(recallamount), group = as.factor(recallamount)), size = 2, alpha = 1 / 3) +\n  geom_line(data = graphRT, mapping = aes(x = serial_position_rel, y = rt, color = as.factor(recallamount), group = as.factor(recallamount))) +\n  geom_errorbar(aes(ymin = rt - se, ymax = rt + se, color = as.factor(recallamount), group = as.factor(recallamount)), width = .15) +\n  scale_colour_manual(values = viridisLite::viridis(2, direction = -1), name = \"List Length\") +\n  xlab(\"Relative Serial Position\") +\n  ylab(\"Mean Response Time (ms)\") +\n  # scale_y_continuous(breaks=seq(600, 1400, 50), limits = c(600, 1400))+\n  # ylim(250, 800) +\n  theme(axis.text.x = element_text(angle = 70, hjust = 1)) +\n  facet_grid(exp ~ ., scales = \"free\") +\n  geom_vline(xintercept = 0.5, color = \"red\")\n```\n\n::: {.cell-output-display}\n![](JointAnalyses-1ab-Ven_files/figure-html/PlotGraphs2-1.png){width=480}\n:::\n:::\n\n\n\n\nSplit based on sample source\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Means for plot, with within-participant SEMs\ngraphRT <- procTrim %>% \n  filter(procPeriod == \"Load\") %>% \n  summarySEwithin(measurevar = \"rt\", withinvars = c(\"recallamount\", \"serial_position_rel\"), betweenvars=c(\"exp\",\"sample\"), idvar=\"participant\") %>% \n  mutate(serial_position_rel = as.numeric(as.character(serial_position_rel)))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAutomatically converting the following non-factors to factors: exp, sample, serial_position_rel\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(graphRT, aes(serial_position_rel, rt)) + \n  geom_point(data = graphRT, mapping = aes(x = serial_position_rel, y = rt, color=as.factor(recallamount), group=as.factor(recallamount)), size = 2, alpha = 1/3) +\n  geom_line(data = graphRT, mapping = aes(x = serial_position_rel, y = rt, color=as.factor(recallamount), group=as.factor(recallamount))) + \n  geom_errorbar(aes(ymin=rt-se, ymax=rt+se, color=as.factor(recallamount), group=as.factor(recallamount)), width=.15)+\n  scale_colour_manual(values = viridisLite::viridis(2, direction = -1), name=\"List Length\") + \n  xlab(\"Relative Serial Position\") + \n  ylab(\"Mean Response Time (ms)\") +\n  # scale_y_continuous(breaks=seq(600, 1400, 50), limits = c(600, 1400))+\n  #ylim(250, 800) +\n  theme(axis.text.x = element_text(angle = 70, hjust=1))+\n  facet_grid(exp~sample, scales=\"free\") +\n  geom_vline(xintercept = 0.5, color=\"red\")\n```\n\n::: {.cell-output-display}\n![](JointAnalyses-1ab-Ven_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n\n\n\nPlot RT collapsed over list-length and experiment, as a function of serial position relative to N. Position 0 means the 2nd item in recall2 condition or the 4th item in the recall4 condition.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Means for plot, with within-participant SEMs\ngraphRT <- procTrim %>% \n  filter(procPeriod == \"Load\") %>% \n  summarySEwithin(measurevar = \"rt\", withinvars = c(\"recallamount\", \"serial_position_rel\"), idvar=\"participant\") %>% \n  mutate(serial_position_rel = as.numeric(as.character(serial_position_rel)))\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nAutomatically converting the following non-factors to factors: serial_position_rel\n```\n\n\n:::\n\n```{.r .cell-code}\nggplot(graphRT, aes(serial_position_rel, rt)) + \n  geom_point(data = graphRT, mapping = aes(x = serial_position_rel, y = rt, color=as.factor(recallamount), group=as.factor(recallamount)), size = 2, alpha = 1/3) +\n  geom_line(data = graphRT, mapping = aes(x = serial_position_rel, y = rt, color=as.factor(recallamount), group=as.factor(recallamount))) + \n  geom_errorbar(aes(ymin=rt-se, ymax=rt+se, color=as.factor(recallamount), group=as.factor(recallamount)), width=.15)+\n  scale_colour_manual(values = viridisLite::viridis(2, direction = -1), name=\"List Length\") + \n  xlab(\"Relative Serial Position\") + \n  ylab(\"Mean Response Time (ms)\") +\n  # scale_y_continuous(breaks=seq(600, 1400, 50), limits = c(600, 1400))+\n  #ylim(250, 800) +\n  theme(axis.text.x = element_text(angle = 70, hjust=1))+\n  geom_vline(xintercept = 0.5, color=\"red\")\n```\n\n::: {.cell-output-display}\n![](JointAnalyses-1ab-Ven_files/figure-html/unnamed-chunk-6-1.png){width=480}\n:::\n:::\n\n\n\n\n## Traditional lmer analysis for quick fit\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!file.exists(R_output_file)) {\n  mldat <- filter(procTrim, procPeriod == \"Load\", serial_position_rel >= 1) %>% \n    mutate(ListLength = as.numeric(as.character(ListLength)))\n  \n  ml1 <- lmer(rt ~ sample + exp + ListLength + recallamount + (recallamount*serial_position_rel||participant), data=mldat)\n  ml2 <- lmer(rt ~ sample + exp + ListLength + recallamount + serial_position_rel + (recallamount*serial_position_rel||participant), data=mldat)\n  ml3 <- lmer(rt ~ sample + exp + ListLength + recallamount + recallamount*serial_position_rel + (recallamount*serial_position_rel||participant), data=mldat)\n}\n\nanova(ml1,ml2,ml3)\n```\n\n::: {.cell-output .cell-output-stderr}\n\n```\nrefitting model(s) with ML (instead of REML)\n```\n\n\n:::\n\n::: {.cell-output .cell-output-stdout}\n\n```\nData: mldat\nModels:\nml1: log(rt) ~ sample + exp + ListLength + recallamount + ((1 | participant) + (0 + recallamount | participant) + (0 + serial_position_rel | participant) + (0 + recallamount:serial_position_rel | participant))\nml2: log(rt) ~ sample + exp + ListLength + recallamount + serial_position_rel + ((1 | participant) + (0 + recallamount | participant) + (0 + serial_position_rel | participant) + (0 + recallamount:serial_position_rel | participant))\nml3: log(rt) ~ sample + exp + ListLength + recallamount + recallamount * serial_position_rel + ((1 | participant) + (0 + recallamount | participant) + (0 + serial_position_rel | participant) + (0 + recallamount:serial_position_rel | participant))\n    npar   AIC   BIC  logLik deviance Chisq Df Pr(>Chisq)    \nml1   14 15222 15335 -7597.2    15194                        \nml2   15 15215 15336 -7592.7    15185  9.03  1   0.002656 ** \nml3   16 15202 15330 -7584.9    15170 15.55  1  8.036e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(ml2)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: log(rt) ~ sample + exp + ListLength + recallamount + serial_position_rel +  \n    ((1 | participant) + (0 + recallamount | participant) + (0 +  \n        serial_position_rel | participant) + (0 + recallamount:serial_position_rel |          participant))\n   Data: mldat\n\nREML criterion at convergence: 15227.7\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.1276 -0.6093 -0.1113  0.5045  5.2728 \n\nRandom effects:\n Groups        Name                              Variance  Std.Dev. Corr \n participant   (Intercept)                       0.0472203 0.21730       \n participant.1 recallamount2                     0.0034342 0.05860       \n               recallamount4                     0.0294753 0.17168  -0.43\n participant.2 serial_position_rel               0.0001665 0.01290       \n participant.3 recallamount2:serial_position_rel 0.0000000 0.00000       \n               recallamount4:serial_position_rel 0.0009663 0.03109   NaN \n Residual                                        0.1104201 0.33230       \nNumber of obs: 22365, groups:  participant, 120\n\nFixed effects:\n                      Estimate Std. Error t value\n(Intercept)          6.5773717  0.0476529 138.027\nsamplestudents       0.1108894  0.0505699   2.193\nexp1b               -0.5117154  0.0416599 -12.283\nListLength          -0.0001424  0.0016343  -0.087\nrecallamount4        0.1839298  0.0200426   9.177\nserial_position_rel  0.0062013  0.0020342   3.049\n\nCorrelation of Fixed Effects:\n            (Intr) smplst exp1b  LstLng rcllm4\nsamplstdnts -0.761                            \nexp1b       -0.303 -0.161                     \nListLength  -0.193  0.000 -0.001              \nrecallamnt4 -0.072  0.000 -0.001 -0.076       \nsrl_pstn_rl  0.006  0.000  0.001 -0.382  0.120\noptimizer (nloptwrap) convergence code: 0 (OK)\nboundary (singular) fit: see help('isSingular')\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(ml3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nLinear mixed model fit by REML ['lmerMod']\nFormula: log(rt) ~ sample + exp + ListLength + recallamount + recallamount *  \n    serial_position_rel + ((1 | participant) + (0 + recallamount |  \n    participant) + (0 + serial_position_rel | participant) +      (0 + recallamount:serial_position_rel | participant))\n   Data: mldat\n\nREML criterion at convergence: 15216.6\n\nScaled residuals: \n    Min      1Q  Median      3Q     Max \n-5.1249 -0.6100 -0.1096  0.5015  5.2442 \n\nRandom effects:\n Groups        Name                              Variance  Std.Dev. Corr \n participant   (Intercept)                       2.549e-02 0.159670      \n participant.1 recallamount2                     2.480e-02 0.157477      \n               recallamount4                     5.193e-02 0.227872 0.50 \n participant.2 serial_position_rel               8.367e-05 0.009147      \n participant.3 recallamount2:serial_position_rel 1.250e-04 0.011182      \n               recallamount4:serial_position_rel 7.099e-04 0.026644 -0.25\n Residual                                        1.103e-01 0.332186      \nNumber of obs: 22365, groups:  participant, 120\n\nFixed effects:\n                                    Estimate Std. Error t value\n(Intercept)                        6.5837464  0.0476067 138.295\nsamplestudents                     0.1120987  0.0505134   2.219\nexp1b                             -0.5143840  0.0416130 -12.361\nListLength                        -0.0001431  0.0016337  -0.088\nrecallamount4                      0.1581450  0.0211093   7.492\nserial_position_rel                0.0042292  0.0021835   1.937\nrecallamount4:serial_position_rel  0.0174225  0.0045932   3.793\n\nCorrelation of Fixed Effects:\n            (Intr) smplst exp1b  LstLng rcllm4 srl_p_\nsamplstdnts -0.761                                   \nexp1b       -0.303 -0.161                            \nListLength  -0.193  0.000 -0.001                     \nrecallamnt4 -0.074  0.000 -0.001 -0.071              \nsrl_pstn_rl -0.003  0.001  0.000 -0.356  0.185       \nrcllmnt4:__  0.034  0.000  0.001 -0.001 -0.322 -0.407\noptimizer (nloptwrap) convergence code: 0 (OK)\nunable to evaluate scaled gradient\nModel failed to converge: degenerate  Hessian with 1 negative eigenvalues\n```\n\n\n:::\n:::\n\n\n\n### BRMS ANALYSES  \n\nFit the preregistered BRMS models. \n\nModel 1 is the model that predicts no increase after position N+1\nModel 2 predicts an equal increase after position N+1 for both recall2 and recall4 condition\nModel 3 includes an interactions between relative position and recall2 vs recall4\n\nFirst, to use the default priors, we need to transform the DV and IVS. DV is log transformed because RTs are skewed, and then z transformed. Continuous predictiors are also z transformed, while categorical predictions are set to sum contrasts.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!file.exists(R_output_file)) {\n  bmldat <- mldat %>% \n    mutate(rt = scale(log(rt))[,1],\n           ListLength = scale(ListLength)[,1],\n           serial_position_rel = scale(serial_position_rel)[,1],\n           exp = as.factor(exp))\n  \n  contrasts(bmldat$recallamount) <- \"contr.sum\"\n  contrasts(bmldat$exp) <- \"contr.sum\"\n  \n  \n  bml1r <- brm(rt ~ exp + ListLength + recallamount + (recallamount*serial_position_rel||participant), data=bmldat, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n  \n  bml2r <- brm(rt ~ exp + ListLength + recallamount + serial_position_rel + (recallamount*serial_position_rel||participant), data=bmldat, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n  \n  bml3r <- brm(rt ~ exp + ListLength + recallamount + serial_position_rel*recallamount + (recallamount*serial_position_rel||participant), data=bmldat, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n}\n```\n:::\n\n\n\n\nView the estimates of the full model:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(bml3r)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: rt ~ exp + ListLength + recallamount + serial_position_rel * recallamount + (recallamount * serial_position_rel || participant) \n   Data: bmldat (Number of observations: 22365) \n  Draws: 4 chains, each with iter = 20000; warmup = 10000; thin = 1;\n         total post-warmup draws = 40000\n\nMultilevel Hyperparameters:\n~participant (Number of levels: 120) \n                                      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)                             0.49      0.03     0.43     0.56 1.00     6317    12031\nsd(recallamount1)                         0.22      0.02     0.19     0.26 1.00     9276    15119\nsd(serial_position_rel)                   0.04      0.01     0.02     0.05 1.00     9781    11736\nsd(recallamount1:serial_position_rel)     0.04      0.01     0.02     0.05 1.00     8196     7753\n\nRegression Coefficients:\n                                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept                             0.11      0.04     0.03     0.20 1.00     2525     5213\nexp1                                  0.54      0.05     0.45     0.63 1.00     2598     5596\nListLength                           -0.00      0.01    -0.01     0.01 1.00    66163    30894\nrecallamount1                        -0.21      0.02    -0.25    -0.17 1.00     5608    10754\nserial_position_rel                   0.04      0.01     0.03     0.06 1.00    46471    31699\nrecallamount1:serial_position_rel    -0.03      0.01    -0.04    -0.01 1.00    49485    31639\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.67      0.00     0.67     0.68 1.00    69962    28168\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n\nCompute bayes factors via bridge sampling:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(5236)\n\nif (!file.exists(R_output_file)) {\n  BF21r <- bayes_factor(bml2r, bml1r)\n  BF32r <- bayes_factor(bml3r, bml2r)\n}\n\nBF21r\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Bayes factor in favor of bml2r over bml1r: 155.88635\n```\n\n\n:::\n\n```{.r .cell-code}\nBF32r\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Bayes factor in favor of bml3r over bml2r: 35.47096\n```\n\n\n:::\n:::\n\n\n\n\nNow, let's run models separately for the recall2 and recall4 conditions, so that we know whether we have evidence specifically for or against increase within each condition\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!file.exists(R_output_file)) {\n  bmldat2 <- filter(bmldat, recallamount == 2)\n  bmldat4 <- filter(bmldat, recallamount == 4)\n  \n  \n  bmlr_r2_1 <- brm(rt ~ exp + ListLength + (serial_position_rel|participant), data=bmldat2, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n  bmlr_r2_2 <- brm(rt ~ exp + ListLength + serial_position_rel + (serial_position_rel|participant), data=bmldat2, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n  \n  bmlr_r4_1 <- brm(rt ~ exp + ListLength + (serial_position_rel|participant), data=bmldat4, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n  bmlr_r4_2 <- brm(rt ~ exp + ListLength + serial_position_rel + (serial_position_rel|participant), data=bmldat4, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n\n}\n```\n:::\n\n\n\n\nCompute bayes factors separately for within recall2 and recall4 condition via bridge sampling:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(5236)\n\nif (!file.exists(R_output_file)) {\n  BFr_r2_2v1 <- bayes_factor(bmlr_r2_2, bmlr_r2_1)\n  BFr_r4_2v1 <- bayes_factor(bmlr_r4_2, bmlr_r4_1)\n}\n\nBFr_r2_2v1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Bayes factor in favor of bmlr_r2_2 over bmlr_r2_1: 0.23612\n```\n\n\n:::\n\n```{.r .cell-code}\nBFr_r4_2v1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Bayes factor in favor of bmlr_r4_2 over bmlr_r4_1: 181.59623\n```\n\n\n:::\n:::\n\n\n\n#### OLD ANALYSES WITHOUT RANDOM SLOPES EFFECTS\n\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!file.exists(R_output_file)) {\n  bmldat <- mldat %>% \n    mutate(rt = scale(log(rt))[,1],\n           ListLength = scale(ListLength)[,1],\n           serial_position_rel = scale(serial_position_rel)[,1],\n           exp = as.factor(exp))\n  \n  contrasts(bmldat$recallamount) <- \"contr.sum\"\n  contrasts(bmldat$exp) <- \"contr.sum\"\n  \n  \n  bml1 <- brm(rt ~ exp + ListLength + recallamount + (1|participant), data=bmldat, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n  bml2 <- brm(rt ~ exp + ListLength + recallamount + serial_position_rel + (1|participant), data=bmldat, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n  bml3 <- brm(rt ~ exp + ListLength + recallamount + serial_position_rel*recallamount + (1|participant), data=bmldat, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n}\n```\n:::\n\n\n\n\nView the estimates of the full model:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsummary(bml3)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n Family: gaussian \n  Links: mu = identity; sigma = identity \nFormula: rt ~ exp + ListLength + recallamount + serial_position_rel * recallamount + (1 | participant) \n   Data: bmldat (Number of observations: 22365) \n  Draws: 4 chains, each with iter = 20000; warmup = 10000; thin = 1;\n         total post-warmup draws = 40000\n\nMultilevel Hyperparameters:\n~participant (Number of levels: 120) \n              Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsd(Intercept)     0.48      0.03     0.42     0.54 1.00     2190     4496\n\nRegression Coefficients:\n                                  Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nIntercept                             0.10      0.04     0.01     0.18 1.00      778     1445\nexp1                                  0.52      0.04     0.43     0.61 1.01      726     1733\nListLength                           -0.00      0.01    -0.01     0.01 1.00    25820    29486\nrecallamount1                        -0.20      0.01    -0.21    -0.19 1.00    23963    27801\nserial_position_rel                   0.04      0.01     0.02     0.05 1.00    18054    24498\nrecallamount1:serial_position_rel    -0.02      0.01    -0.03    -0.01 1.00    23181    27603\n\nFurther Distributional Parameters:\n      Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS\nsigma     0.70      0.00     0.69     0.71 1.00    35381    30595\n\nDraws were sampled using sampling(NUTS). For each parameter, Bulk_ESS\nand Tail_ESS are effective sample size measures, and Rhat is the potential\nscale reduction factor on split chains (at convergence, Rhat = 1).\n```\n\n\n:::\n:::\n\n\n\n\nCompute bayes factors via bridge sampling:\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(5236)\n\nif (!file.exists(R_output_file)) {\n  BF21 <- bayes_factor(bml2, bml1)\n  BF32 <- bayes_factor(bml3, bml2)\n}\n\nBF21\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Bayes factor in favor of bml2 over bml1: 37.70294\n```\n\n\n:::\n\n```{.r .cell-code}\nBF32\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Bayes factor in favor of bml3 over bml2: 11.91208\n```\n\n\n:::\n:::\n\n\n\n\nNow, let's run models separately for the recall2 and recall4 conditions, so that we know whether we have evidence specifically for or against increase within each condition\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nif (!file.exists(R_output_file)) {\n  bmldat2 <- filter(bmldat, recallamount == 2)\n  bmldat4 <- filter(bmldat, recallamount == 4)\n  \n  \n  bml_r2_1 <- brm(rt ~ exp + ListLength + (1|participant), data=bmldat2, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n  bml_r2_2 <- brm(rt ~ exp + ListLength + serial_position_rel + (1|participant), data=bmldat2, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n  \n  bml_r4_1 <- brm(rt ~ exp + ListLength + (1|participant), data=bmldat4, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n  bml_r4_2 <- brm(rt ~ exp + ListLength + serial_position_rel + (1|participant), data=bmldat4, \n             save_all_pars = TRUE, iter = 20000, cores = 4, chains = 4)\n\n}\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(5236)\n\nif (!file.exists(R_output_file)) {\n  BF_r2_2v1 <- bayes_factor(bml_r2_2, bml_r2_1)\n  BF_r4_2v1 <- bayes_factor(bml_r4_2, bml_r4_1)\n}\n\nBF_r2_2v1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Bayes factor in favor of bml_r2_2 over bml_r2_1: 0.60844\n```\n\n\n:::\n\n```{.r .cell-code}\nBF_r4_2v1\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nEstimated Bayes factor in favor of bml_r4_2 over bml_r4_1: 358.33508\n```\n\n\n:::\n:::\n\n\n\n\nsave the estimated models to avoid fitting them again in the future\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# save.image(here::here('output/exp1_updated.RData'))\n```\n:::\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}